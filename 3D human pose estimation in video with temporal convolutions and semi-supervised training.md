# 3D human pose estimation in video with temporal convolutions and semi-supervised training



## Abstract

​	在这篇paper中， 我们展示了视频中的3D姿态可以通过基于 **在2D关键点上扩张的时域卷积** 的全卷积模型来进行有效的预测 我们引进一种反响投影的简单、有效的半监督训练方法。这种方法使用的数据是未标注的视频数据。

​	首先我们使用已经预测好的2D关键点视频（未标注）作为输入，然后预测3D姿态， 最后反向投影回输入的2D关键点。



## Introduce

​	我们的工作集中在视频中的3D人体姿态预测，我们使用了一种最新的方法，它首先进行2D关键点检测，然后进行3D关键点预测。尽管这种方法可以减少任务的难度，但是因为多个3D关键点可以映射到同一个2D关键点，因此它本质上是有歧义的。

​	之前的工作，处理这种歧义性是通过RNN建立带有时域信息的模型。另一方面，卷积网络在处理带有时域信息的任务也很成功（传统是用RNN），例如神经机器翻译、语言建模、语音生成、语音识别。对比与RNN，CNN有一大优势，它可以并行的处理多个框架。

![](https://raw.githubusercontent.com/lxy5513/Markdown_image_dateset/master/Xnip2018-12-29_15-19-05.png)

​	在这篇paper中，我们展示了一种全卷集架构，它在2D关键点上实施时域卷积操作，在视频中得到精确的3D姿态预测。我们的方法可以兼容任何的2D关键点检测器，并且通过扩充的卷积维度，可以有效的处理大的上下文信息。比较于基于RNN的方法，它准确率更高、简洁、有效（无论是从计算复杂度还是从参数数目的角度）。

​	有了高的准确率和有效的架构，我们转向去处理一些只有很少带标签的训练数据集，然后引进一种新的策略去使用未标签的视频数据集进行半监督学习。带标签的资源不足时3D视频姿态预测的最大挑战，因为一般来说这种模型需要大量的标签数据。我们的方法受到了非监督机器翻译的启发（句子从一种语言被翻译到另一种语言， 然后在翻译回原语言），具体来说，我们使用无标签的2D视频，通过现有的姿态检测器预测出3D姿态，然后再映射回2D空间。

​	总结，这篇paper有两大贡献：第一，对于3D姿态预测，我们展示了一种基于2D关键点轨迹之上扩张出一种时域卷积方法，它兼具简洁和高效的特性。在相同精确度的基准之上，我们的模型不管在计算复杂度上还是在模型参数上都要比基于RNN的模型更加简洁。

​	第二，我们引进一种半监督的方法来处理未标记的视频，在缺少标签数据的情况下也可以取得好的效果。比较于之前的半监督方法，只需要照相机原来的一些参数，不需要实际的2D标签数据或者照相机之外的其他参数。



## 2 Related Work

​	在深度学习取得成功之前，大多数进行3D姿态预测的方法都是基于特征工程和假设骨架和关节的流动性来完成的。第一种基于卷积神经网络的方法聚焦于端到端的重建，无需中间监督，直接从RGB图片来预测3D姿态。

​	另一种是**Two-step pose estimation**， 这是一种新的3D预测家族，他是基于性能最好的2D关键点检测器，第一步在图片空间中预测出关节点的位置，接下来在转移到3D空间。这种模式的性能要好于第一种，因为它利用了中间监督的特性。早起的方法从一个大的2D关键点集合中通过k最邻近算法来搜索出预测的关键点集合，然后简单的输出对应的3D关键点。一些方法图片特性和实际的姿态。另外，可以通过对一组2D关键点对它们的深度预测来生成3D姿态。

​	**Video pose estimation**. 之前的大多数预测都是在单帧的环境中， 但最近的一些工作，通过处理视频，通过利用其时域信息，产生出更健壮的预测、对噪声也有了更好的抗性。比如：从时空体积块（spatial-temporal volumes) 的梯度直方图（HoG histograms of oriented gradients）中推断出3D姿态。通过Bi-directional LSTMs 精调(refine)从单张图片预测出的3D姿态。然而最成功的方法是学习2D关键点的轨迹，我们便是基于这种方法。

​	最近，LSTM序列到序列的学习模型很受欢迎，它将是视频中的一个2D姿态序列编码到一个固定的向量中去，然后再对这个向量解码到3D姿态中。然而输入和输出的序列有相同的长度，一个确定的2D姿态传输是一个更自然的选择。我们的带有seq2seq模型表明输出的姿态趋向于很长的序列。处理这个问题可以以时间连续性为代价，每5帧重新初始化一下这个编码器。考虑到之前身体部位的连续性，RNN方法也可以得到相同的效果。

​	**半监督训练**。这些可以用于多任务网络：2D、3D姿态预测和动作识别， 使用2D/3D标签的Human3.6M数据集和仅仅有2D标签的MPII数据集。未标签的多角度视频数据集也被用于3D姿态预训练表示。在第二个数据集中（仅仅有2D姿态标记），GAN可以不真实的2D姿态中辨别实际的2D姿态。`Ordinal depth
supervision for 3d human pose estimation`提出了一种弱监督学习的方法，它基于序列的深度标记，通过深度对比增强数据集，比如：这个右腿在左腿之后。我们的工作不同于以上，我们并没有使用heatmap,而是通过检测关键点的坐标来描述姿态，