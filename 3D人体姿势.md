# 3D人体姿势

## 基础

### 难度

理解 3D 空间一直面临着几个难题。

第一个问题涉及到「自遮挡」和「正常遮挡」的问题，

以及大量 3D 形状都能符合单个 2D 表示的特征。由于无法将相同结构的不同图像映射到相同的 3D 空间以及处理这些表示的多模态，对这些问题的理解变得更加复杂 [ 94 ]。

最后，实况的 3D 数据集通常相当昂贵且难以获得，加上表示 3D 结构的方法各异，这些都导致了模型训练的局限性。



### UV贴图

一、理解UV贴图
UVs是驻留在多边形网格顶点上的两维纹理坐标点，它们定义了一个两维纹理坐标系统，称为UV纹理空间，这个空间用U和V两个字母定义坐标轴。用于确定如何将一个纹理图像放置在三维的模型表面。
本质上，UVs是提供了一种模型表面与纹理图像之间的连接关系，UVs负责确定纹理图像上的一个点（像素）应该放置在模型表面的哪一个顶点上，由此可将整个纹理都铺盖到模型上。如果没有UVs，多边形网格将不能被渲染出纹理。

三、UV贴图
为一个表面创建UVs的过程叫UV贴图（UV mapping）。这个过程包括创建、编辑。其结果是明确地决定图像如何在三维模型上显示，这项技术的熟练程度直接影响模型的最后表现。



## 1 DensePose

#### Dense Human Pose Estimation

Partitioning the surface

- break the surface into parts 
- parameterize each part with loacl 2D system

人体表面的全方位观察，把每个人变成UV贴图，一片一片一片，一片。系统可以覆盖浑身上下超过5000个节点，比十几个关节要细致得多.



![](https://raw.githubusercontent.com/lxy5513/Markdown_image_dateset/master/Xnip2018-12-28_20-22-20.png)





## **02 Learning to Estimate 3D Human Pose and Shape From a Single Color Image**

#### 学习从单色图像估计3D人体姿态和形状

1. 端到端框架内引入参数化统计人体形态模型（SMPL) 
   - 获得非常详细的三维网格效果
   - 同时仅需要估计少量参数
   - 使其直接网络预测更为友好
2. 从2D关键点和掩膜才能可靠的预测这些参数
3. 根据估计的参数生成3D网格，并使用3D每顶点损耗为曲面的显示优化
4. 采用可微分渲染器将3D网格投影到图像上，通过优化投影和2D注释（即2D关键点和掩膜）的一致性，可以进一步细化网络。



## 03  Automatic Estimation of 3D Human Pose and Shape from a Single Image

这种方法首先预测 2D 人体关节的位置，然后使用另一个称为 SMPL 的模型来创建 3D 身体形状网格，从而允许它从 2D 姿态估计理解 3D 形态。3D 网格能够同时捕捉姿态和形状，而以前的方法只能得到 2D 人体姿势。作者提供了一个优秀的视频，并在视频中分析了他们的工作：https://www.youtube.com/watch?v=eUnZ2rjxGaE 

我们描述了第一种（从一张无约束图像）自动估计人体 3D*姿态以及 3D* 人体形状的方法。我们估计一个完整的 3D网格，并表明仅仅 2D 关节就携带了大量的身体形状的信息。由于人体的复杂性、清晰度、遮挡情况、衣服、照明条件以及从 2D 推断 3D 所固有的模糊性，致使这个问题极具挑战性。



## 04 Synthetic Occlusion Augmentation for 3D Human Pose Estimation with Volumetric Heatmaps

使用完全卷积骨架结构，我们获得每个身体关节的体积热图，我们使用soft-argmax将其转换为坐标。绝对人中心深度由1D热图预测头估计。坐标被反投影到3D相机空间，在那里我们最小化L1损失。

我们良好结果的关键是使用来自Pascal VOC数据集的随机放置的遮挡物进行训练数据增强。

![](https://raw.githubusercontent.com/lxy5513/Markdown_image_dateset/master/Xnip2018-12-29_11-28-08.png)



### 相关工作：

3D人体姿势估计。最先进的3D姿态估计方法基于深度卷积神经网络。我们推荐Sarafianos等人的调查[19]来概述方法。最近，基于从2D人体姿态估计获得的经验（例如，[13]），已经引入了基于热图的方法用于具有有希望的结果的3D姿态估计。这包括**体积和边际热图**。遮挡增强。**擦除或粘贴图像**的某些部分已成功用作图像分类，对象检测，人员重新识别[27]\[1] \[3]\[2][5]以及面部面部标志局部的数据增强化[26]。 Ke等人。 [10]通过复制来增强用于2D姿势估计的图像一些身体关节的背景补丁。我们最近发现这种技术对于3D姿态估计也非常有效[20]。

### 图像预处理。

我们使用YOLOv3探测器[18]获得人类边界框。将原始相机的焦距f作为全局超参数处理，我们将图像重新投影到人物盒的中心，其中盒子的较大边填充90％的输出。

### 骨干网。

我们将裁剪和缩放的图像（256 256 px）送入完全卷积的骨干网络（ResNet v2-50）。我们通过在主干的最后空间特征图上添加1x1卷积层直接**从骨干网获得体积热图**，产生J D输出通道。产生的张量被重新塑造以产生**J体积**，每个身体关节一个，每个具有**深度D**.

![](https://raw.githubusercontent.com/lxy5513/Markdown_image_dateset/master/Xnip2018-12-29_11-33-17.png)

### 体积热图。

我们遵循Pavlakos等人。在体积热图的轴[17]的解释中：X和Y对应于图像空间和相对于人体中心的相机空间的深度轴。然而，当从图像反向投影到相机空间时，相对深度是不够的。 Pavlakos等。基于骨骼长度先验，优化后处理中的根关节深度。相比之下，我们使用骨干网上的第二个预测头来预测它（见图1）。这将输出一个离散为32个单位的1D热图，代表相机前方10米的范围。

![](https://raw.githubusercontent.com/lxy5513/Markdown_image_dateset/master/Xnip2018-12-29_12-09-32.png)

### soft-argmax

我们使用soft-argmax [11][15]从热图提取坐标预测。由于此操作是可区分的，因此无需在训练时提供地面真实热图[24]。相反，可以在网络中更深地计算损失并通过soft-argmax操作反向传播。 Soft-argmax还可以减少硬argmax固有的量化误差，并提供细粒度，连续的结果，而无需内存昂贵的高分辨率热图[24]

### 相机内在

预测图像坐标xi，yi，深度通过soft-argmax协调相对于人中心的ΔZi和人体中心的绝对深度Z *，我们现在需要相机内在函数从图像空间移动到3D相机空间。如前所述，原始相机的焦距f被视为超参数，我们还必须考虑在预处理中应用的缩放因子。

为了避免对f进行精确的超参数调整，我们在训练期间学习了一个额外的，与输入无关的校正因子c，以实现更好的图像和热图位置对齐。将图像高度和宽度表示为H和W，将反投影表示为Loss。在减去根关节坐标后，我们计算原始相机空间中的L1损失w.r.t.所提供的根本相对的基本事实。没有使用明确的热图丢失。由于以上所有操作都是可区分的，因此可以对整个网络进行端到端的培训。

### 数据扩充

在我们最近关于3D姿态估计的遮挡鲁棒性的研究中[20]，我们发现用合成遮挡增强训练图像是一种有效的正则化器。从Pascal VOC数据集[4]中的对象开始，我们过滤掉人员，标记为难或截断的区段以及区域低于500 px的区段，留下2638个对象。使用概率pocc，我们在每个帧的随机位置粘贴这些对象的随机数（1到8之间）。我们还应用标准几何增强（缩放，旋转，平移，水平翻转）和外观扭曲（模糊和颜色操作）。在测试时，仅使用水平翻转增强。

### 训练细节

骨干网用[21]中的ImageNet预训练权重初始化。我们使用Adam优化器和循环（三角形）学习速率训练关于训练和验证集合的410个时期的最终方法[22]。我们使用快照集合[7]制作了最终的挑战预测，对在周期性时间表的最后三个学习率 - 最小值下拍摄的快照的预测进行了平均。我们设置f = 1500和pocc = 0.5。

### 结果

评估度量是减去根关节位置后所有关节的每个关节位置误差（MPJPE）的平均值。我们的方法在Challenge测试集上达到45.2 mm MPJPE，其次是最佳方法，分别达到47.8,52.6,58.7,59.0,59.5,66.2,66.5。